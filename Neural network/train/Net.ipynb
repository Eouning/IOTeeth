{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f53c768",
   "metadata": {},
   "source": [
    "# 导入库及自定义函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1c824",
   "metadata": {},
   "source": [
    "## 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45d9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import os, random, shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from itertools import cycle\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from visdom import Visdom\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset,ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a23e2",
   "metadata": {},
   "source": [
    "## 自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3479ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltshow(img):\n",
    "    \"\"\"\n",
    "    介绍：在Jupyter界面上展示图片。转变了numpy数组的颜色空间，使图片色彩符合直觉 \\n\n",
    "    传入变量： \\n\n",
    "            img:传入的图片 \\n\n",
    "    传出变量： \\n\n",
    "            无 \\n\n",
    "    \"\"\"\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #颜色空间转换函数\n",
    "    plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.xticks([]), plt.yticks([]) # 隐藏 X 和 Y 轴的刻度值\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda245e9",
   "metadata": {},
   "source": [
    "# 训练集制作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e6dc5a",
   "metadata": {},
   "source": [
    "## 标签定义\n",
    "    健康-0\n",
    "    caries-1\n",
    "    Calculus-2\n",
    "    Gingivitis-3\n",
    "    hypodontia-4\n",
    "    Discoloration-5\n",
    "    Ulcer-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b392997",
   "metadata": {},
   "source": [
    "## 移动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca362fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "type_name=\"Ulcer\"\n",
    "dir_name=\"tooth/Ulcer/preview/\"\n",
    "\n",
    "save_dir=\"datas/\"\n",
    "name_list=os.listdir(dir_name)\n",
    "#print(name_list)\n",
    "sum=-1\n",
    "for name in name_list:\n",
    "    sum+=1\n",
    "    with open('datas/label/'+type_name+str(sum)+'.txt','w') as f1:\n",
    "        f1.write('6')\n",
    "    im=cv2.imread(dir_name+name)\n",
    "    cv2.imwrite('datas/images/'+type_name+str(sum)+'.jpg',im)\n",
    "\"\"\"\n",
    "print(\"完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11343134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimg_dir='images/'\\nname_list=os.listdir(img_dir)\\nsum=0\\nfor name in name_list:\\n    if os.path.exists(img_dir+name+'/Out_image.jpg'):\\n        sum+=1\\n        with open(img_dir+name+'/label.txt') as f1:\\n            with open('datas/label/'+str(sum)+'.txt','w') as f2:\\n                f2.write(f1.read())\\n        im=cv2.imread(img_dir+name+'/Ori_image.jpg')\\n        cv2.imwrite('datas/images/'+str(sum)+'.jpg',im)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "img_dir='images/'\n",
    "name_list=os.listdir(img_dir)\n",
    "sum=0\n",
    "for name in name_list:\n",
    "    if os.path.exists(img_dir+name+'/Out_image.jpg'):\n",
    "        sum+=1\n",
    "        with open(img_dir+name+'/label.txt') as f1:\n",
    "            with open('datas/label/'+str(sum)+'.txt','w') as f2:\n",
    "                f2.write(f1.read())\n",
    "        im=cv2.imread(img_dir+name+'/Ori_image.jpg')\n",
    "        cv2.imwrite('datas/images/'+str(sum)+'.jpg',im)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce46727",
   "metadata": {},
   "source": [
    "## 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2747e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef moveimg(fileDir, tarDir):\\n    pathDir = os.listdir(fileDir)  # 取图片的原始路径\\n    filenumber = len(pathDir)\\n    rate = 0.1  # 自定义抽取图片的比例，比方说100张抽10张，那就是0.1\\n    picknumber = int(filenumber * rate)  # 按照rate比例从文件夹中取一定数量图片\\n    sample = random.sample(pathDir, picknumber)  # 随机选取picknumber数量的样本图片\\n    print(sample)\\n    for name in sample:\\n        shutil.move(fileDir + name, tarDir + \"/\" + name)\\n    return\\n \\ndef movelabel(file_list, file_label_train, file_label_val):\\n    for i in file_list:\\n        if i.endswith(\\'.jpg\\'):\\n            # filename = file_label_train + \"\\\\\" + i[:-4] + \\'.xml\\'  # 可以改成xml文件将’.txt‘改成\\'.xml\\'就可以了\\n            filename = file_label_train + \"/\" + i[:-4] + \\'.txt\\'  # 可以改成xml文件将’.txt‘改成\\'.xml\\'就可以了\\n            if os.path.exists(filename):\\n                shutil.move(filename, file_label_val)\\n                print(i + \"处理成功！\")\\nif __name__ == \\'__main__\\':\\n    fileDir = r\\'datas/images\\'+ \"/\"  # 源图片文件夹路径\\n    tarDir = r\\'datas/images_val\\'  # 图片移动到新的文件夹路径\\n    moveimg(fileDir, tarDir)\\n    file_list = os.listdir(tarDir)\\n    file_label_train = \\'datas/label\\' # 源图片标签路径\\n    file_label_val = \\'datas/label_val\\'  # 标签\\n      # 移动到新的文件路径\\n    movelabel(file_list, file_label_train, file_label_val)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def moveimg(fileDir, tarDir):\n",
    "    pathDir = os.listdir(fileDir)  # 取图片的原始路径\n",
    "    filenumber = len(pathDir)\n",
    "    rate = 0.1  # 自定义抽取图片的比例，比方说100张抽10张，那就是0.1\n",
    "    picknumber = int(filenumber * rate)  # 按照rate比例从文件夹中取一定数量图片\n",
    "    sample = random.sample(pathDir, picknumber)  # 随机选取picknumber数量的样本图片\n",
    "    print(sample)\n",
    "    for name in sample:\n",
    "        shutil.move(fileDir + name, tarDir + \"/\" + name)\n",
    "    return\n",
    " \n",
    "def movelabel(file_list, file_label_train, file_label_val):\n",
    "    for i in file_list:\n",
    "        if i.endswith('.jpg'):\n",
    "            # filename = file_label_train + \"\\\\\" + i[:-4] + '.xml'  # 可以改成xml文件将’.txt‘改成'.xml'就可以了\n",
    "            filename = file_label_train + \"/\" + i[:-4] + '.txt'  # 可以改成xml文件将’.txt‘改成'.xml'就可以了\n",
    "            if os.path.exists(filename):\n",
    "                shutil.move(filename, file_label_val)\n",
    "                print(i + \"处理成功！\")\n",
    "if __name__ == '__main__':\n",
    "    fileDir = r'datas/images'+ \"/\"  # 源图片文件夹路径\n",
    "    tarDir = r'datas/images_val'  # 图片移动到新的文件夹路径\n",
    "    moveimg(fileDir, tarDir)\n",
    "    file_list = os.listdir(tarDir)\n",
    "    file_label_train = 'datas/label' # 源图片标签路径\n",
    "    file_label_val = 'datas/label_val'  # 标签\n",
    "      # 移动到新的文件路径\n",
    "    movelabel(file_list, file_label_train, file_label_val)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455e406",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8818d1",
   "metadata": {},
   "source": [
    "## 相关自定义函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58366cc1",
   "metadata": {},
   "source": [
    "### DataLoader制作函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d05878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_loader(data_train,data_label,batch_size=200, shuffle=False):\n",
    "    \"\"\"\n",
    "    介绍：制作DataLoader \\n\n",
    "    传入变量: \\n\n",
    "            data_train:传入的图片集合 \\n\n",
    "            data_label:传入的标签集合 \\n\n",
    "            batch_size:每一组的数据数量，用于划分训练集 \\n\n",
    "            shuffle:是否对传入的数据及进行随机打乱 \\n\n",
    "    传出变量： \\n\n",
    "            data_loader:传出制作好的DataLoader \\n\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = TensorDataset(data_train,data_label)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)#shuffle是是否打乱数据集，可自行设置\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefb5a3",
   "metadata": {},
   "source": [
    "### 数据集读取和制作函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94f6a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(fileDir,tarDir,file_label_train,file_label_val,batch_size=200,shuffle=False):\n",
    "    \"\"\"\n",
    "    介绍：从文件中读取数据并制作数据集 \\n\n",
    "    传入变量: \\n\n",
    "            fileDir:训练图片文件夹路径 \\n\n",
    "            tarDir:验证图片文件夹路径 \\n\n",
    "            file_label_train:训练标签文件夹路径 \\n\n",
    "            file_label_val:验证标签文件夹路径 \\n\n",
    "            batch_size:每一组的数据数量，用于划分训练集 \\n\n",
    "            shuffle:是否对传入的数据及进行随机打乱 \\n\n",
    "    传出变量： \\n\n",
    "            train_loader:传出制作好的训练数据集 \\n\n",
    "            test_loader:传出制作好的验证数据集 \\n\n",
    "    \"\"\"\n",
    "    \n",
    "    transf = torchvision.transforms.ToTensor()  # 实例化类\n",
    "    device=torch.device('cuda:0')  #在GPU上运行\n",
    "    \n",
    "    img_list=[]\n",
    "    label_list=[]\n",
    "    img_list_val=[]\n",
    "    label_list_val=[]\n",
    "    name_list = os.listdir(fileDir)\n",
    "    name_val_list = os.listdir(tarDir)\n",
    "    for name in name_list:\n",
    "        f=open(file_label_train+'/'+name[:-4]+'.txt')\n",
    "        text=f.read()\n",
    "        if text=='':\n",
    "            print('训练集 '+name+' 的标签为空')\n",
    "            f.close()\n",
    "        else:\n",
    "            im=cv2.imread(fileDir+'/'+name)\n",
    "            #lenth=max([im.shape[0],im.shape[1]])\n",
    "            label_list.append(int(text))\n",
    "            im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "            img_list.append(transf(im))\n",
    "            f.close\n",
    "\n",
    "    for name in name_val_list:\n",
    "        f=open(file_label_val+'/'+name[:-4]+'.txt')\n",
    "        text=f.read()\n",
    "        if text=='':\n",
    "            print('训练集 '+name+' 的标签为空')\n",
    "            f.close()\n",
    "        else:\n",
    "            im=cv2.imread(tarDir+'/'+name)\n",
    "            #lenth=max([im.shape[0],im.shape[1]])\n",
    "            label_list_val.append(int(text))\n",
    "            im=cv2.resize(im,(128,128), interpolation = cv2.INTER_CUBIC)\n",
    "            img_list_val.append(transf(im))\n",
    "            f.close\n",
    "\n",
    "\n",
    "    data=torch.stack(img_list)\n",
    "    data_val=torch.stack(img_list_val)\n",
    "    target=torch.tensor(label_list)\n",
    "    target_val=torch.tensor(label_list_val)\n",
    "\n",
    "    data=data.to(torch.float32)\n",
    "    data_val=data_val.to(torch.float32)\n",
    "    target=target.to(torch.long)\n",
    "    target_val=target_val.to(torch.long)\n",
    "                        \n",
    "    print('')\n",
    "    print('训练图片集规模：',data.shape)\n",
    "    print('训练标签集规模：',target.shape)\n",
    "    print('验证图片集规模：',data_val.shape)\n",
    "    print('验证标签集规模：',target_val.shape)\n",
    "    \n",
    "    train_loader,test_loader=Make_loader(data,target,batch_size,shuffle) , Make_loader(data_val,target_val,batch_size,False)\n",
    "    return train_loader,test_loader  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdb0310",
   "metadata": {},
   "source": [
    "### ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "394e050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):\n",
    "        super(CommonBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        x += identity\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class SpecialBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride):\n",
    "        super(SpecialBlock, self).__init__()\n",
    "        self.change_channel = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride[0], padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channel)\n",
    "        )\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride[0], padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride[1], padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.change_channel(x)\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        x += identity\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "\n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet34, self).__init__()\n",
    "        self.prepare = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, 2, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1)\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            CommonBlock(64, 64, 1),\n",
    "            CommonBlock(64, 64, 1),\n",
    "            CommonBlock(64, 64, 1)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            SpecialBlock(64, 128, [2, 1]),\n",
    "            CommonBlock(128, 128, 1),\n",
    "            CommonBlock(128, 128, 1),\n",
    "            CommonBlock(128, 128, 1)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            SpecialBlock(128, 256, [2, 1]),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1),\n",
    "            CommonBlock(256, 256, 1)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            SpecialBlock(256, 512, [2, 1]),\n",
    "            CommonBlock(512, 512, 1),\n",
    "            CommonBlock(512, 512, 1)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 7)  #分类数在这改\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.prepare(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e8b5e",
   "metadata": {},
   "source": [
    "### 网络训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2be1f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_loader,test_loader,learn_rate,epochs,batch_size,save_dir):\n",
    "    \"\"\"\n",
    "    介绍：网路训练函数。训练可中断，同时保留训练效果。本函数使用了visdom以可视化数据。使用命令 python -m visdom.server 打开visdom \\n\n",
    "         可视化训练效果网址：http://localhost:8097 \\n\n",
    "    传入变量: \\n\n",
    "            model:要训练的模型 \\n\n",
    "            train_loader:训练数据集 \\n\n",
    "            test_loader:验证数据集 \\n\n",
    "            tarDir:验证图片文件夹路径 \\n\n",
    "            learn_rate:学习率 \\n\n",
    "            epochs:训练轮数 \\n\n",
    "            batch_size:每一组的数据数量，用于划分训练集 \\n\n",
    "            save_dir:存储模型的文件夹 \\n\n",
    "    传出变量： \\n\n",
    "            无 \\n\n",
    "    \"\"\"\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device=torch.device('cuda:0')  #在GPU上运行\n",
    "\n",
    "    optimizer=torch.optim.Adam(model.parameters(), learn_rate)\n",
    "    loss_fun=nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    if save_dir[-1]!=\"/\":\n",
    "        save_dir=save_dir+'/'\n",
    "\n",
    "    \"\"\"\n",
    "    #使用命令 python -m visdom.server 打开visdom\n",
    "    #网址：http://localhost:8097\n",
    "    viz=Visdom()\n",
    "    viz.line([0.],[0.],win='train_loss',opts=dict(title='train loss'))\n",
    "    viz.line([[0.0,0.0]],[0.],win='test',opts=dict(title='test loss&acc',\n",
    "                                               legend=['loss','acc']))\n",
    "    \"\"\"\n",
    "\n",
    "    best=0\n",
    "    step_Tr=0\n",
    "    step_Te=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        \n",
    "            step_Tr+=1\n",
    "        \n",
    "            data,target=data.to(device),target.to(device)\n",
    "        \n",
    "            logits=model(data)\n",
    "            loss=loss_fun(logits,target)\n",
    "        \n",
    "            #viz.line([loss.item()],[step_Tr],win='train_loss',update='append')\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            if batch_idx %100.==0:\n",
    "                print('训练轮数: {} [{}/{} ({:.0f}%) ]\\tLoss: {:.9f}'.format(\n",
    "                    epoch,batch_idx*len(data),len(train_loader.dataset),\n",
    "                        100*(batch_idx*len(data))/len(train_loader.dataset),loss.item()))\n",
    "        test_loss=0\n",
    "        correct=0\n",
    "        step_Te+=1\n",
    "        \n",
    "        for data,target in test_loader:\n",
    "        \n",
    "            data,target=data.to(device),target.to(device)\n",
    "            \n",
    "            logits=model(data)\n",
    "            test_loss+=loss_fun(logits,target).item()*len(data)\n",
    "    \n",
    "            pred=logits.data.max(1)[1]\n",
    "            correct +=pred.eq(target.data).sum()\n",
    "                    \n",
    "        test_loss/=len(test_loader.dataset)\n",
    "\n",
    "        #viz.line([[test_loss,correct.cpu()/len(test_loader.dataset)]],\n",
    "                        #[step_Te],win='test',update='append')\n",
    "    \n",
    "        print('\\n结果验证: 平均损失: {:.9f},准确率: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss,correct,len(test_loader.dataset), \n",
    "        100.*correct/len(test_loader.dataset)))\n",
    "        \n",
    "        if 100.*correct/len(test_loader.dataset)>best:\n",
    "            best=100.*correct/len(test_loader.dataset)\n",
    "            model_save(model,save_dir+str(batch_size)+\"|\"+str(epoch)+'|'+str(float(100.*correct/len(test_loader.dataset)))+'.pth')\n",
    "            print(\"<--------->\")\n",
    "            print(\"第\"+str(epoch)+\"轮保存成功\")\n",
    "            print(\"<--------->\")\n",
    "\n",
    "    print('训练结束！')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9c872",
   "metadata": {},
   "source": [
    "### 网络保存函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a7cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_save(model,path):\n",
    "    \"\"\"\n",
    "    介绍：保存模型为权重文件 \\n\n",
    "    传入变量: \\n\n",
    "            model:要保存权重的模型 \\n\n",
    "            path:要保存的路径 \\n\n",
    "    传出变量： \\n\n",
    "            无 \\n\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(),path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2622f1",
   "metadata": {},
   "source": [
    "### 图像结果输出函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15a52fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_show(img,model):\n",
    "    \"\"\"\n",
    "    介绍：验证模型对单张图片的识别情况 \\n\n",
    "    传入变量: \\n\n",
    "            img:需识别的图片 \\n\n",
    "            model:要验证的模型 \\n\n",
    "    传出变量： \\n\n",
    "            num:预测结果(int型数字) \\n\n",
    "    \"\"\"\n",
    "    device=torch.device('cuda:0')  #在GPU上运行\n",
    "    transf = torchvision.transforms.ToTensor()  # 实例化类\n",
    "    img_list=[]\n",
    "    im=cv2.resize(img,(128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "    img_list.append(transf(im))\n",
    "    data=torch.stack(img_list)\n",
    "    data=data.to(torch.float32)\n",
    "    logits=model(data.to(device))\n",
    "    num=int(logits.data.max(1)[1].tolist()[0])\n",
    "    #print('预测结果为：',num)\n",
    "    \n",
    "    return(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44fbc8",
   "metadata": {},
   "source": [
    "### 权重加载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d27d1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(model,path):\n",
    "    \"\"\"\n",
    "    介绍：将权重文件加载到模型上 \\n\n",
    "    传入变量: \\n\n",
    "            model:要加载权重的模型 \\n\n",
    "            path:要加载的权重的路径 \\n\n",
    "    传出变量： \\n\n",
    "            无 \\n\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee3677",
   "metadata": {},
   "source": [
    "### 合并两个DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c8505a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Merge_loader(Loader_1, Loader_2, batch_size, shuffle):\n",
    "    \"\"\"\n",
    "    介绍：本函数可混合两个DataLoader \\n\n",
    "    传入变量: \\n\n",
    "            Loader_1:混合对象1 \\n\n",
    "            Loader_2:混合对象2 \\n\n",
    "            batch_size:每个batch的size \\n\n",
    "            shuffle:是否随即打乱数据 \\n\n",
    "    传出变量： \\n\n",
    "            merged_dataloader:混合后的DataLoader \\n\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将两个 DataLoader 的数据集合并为一个 ConcatDataset 对象\n",
    "    dataset_1=Loader_1.dataset\n",
    "    \n",
    "    img_list=[]\n",
    "    label_list=[]\n",
    "    for x in range(len(Loader_2.dataset)):\n",
    "        img_list.append(Loader_2.dataset[x][0])\n",
    "        label_list.append(Loader_2.dataset[x][1])\n",
    "        \n",
    "    data=torch.stack(img_list)\n",
    "    target=torch.tensor(label_list)\n",
    "    data=data.to(torch.float32)\n",
    "    target=target.to(torch.long)\n",
    "    \n",
    "    dataset_2 = TensorDataset(data,target)\n",
    "        \n",
    "    concat_dataset = ConcatDataset([dataset_1,dataset_2])\n",
    "    \n",
    "    # 创建合并后的 DataLoader 对象\n",
    "    merged_dataloader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return merged_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a72e1ee",
   "metadata": {},
   "source": [
    "## 网络训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a4d11",
   "metadata": {},
   "source": [
    "### 需要的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "361e6849",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate=1e-4   #学习率，防止过拟合\n",
    "epochs=800   #训练轮数\n",
    "batch_size=10   #数据集的划分量\n",
    "shuffle=True   #生成数据集时是否打乱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df2265",
   "metadata": {},
   "source": [
    "### 制作data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c735d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datas/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loader,test_loader\u001b[38;5;241m=\u001b[39m\u001b[43mget_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatas/images\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatas/images_val\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatas/label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatas/label_val\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m, in \u001b[0;36mget_loader\u001b[0;34m(fileDir, tarDir, file_label_train, file_label_val, batch_size, shuffle)\u001b[0m\n\u001b[1;32m     21\u001b[0m img_list_val\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     22\u001b[0m label_list_val\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m---> 23\u001b[0m name_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileDir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m name_val_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(tarDir)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m name_list:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datas/images'"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader=get_loader('datas/images','datas/images_val','datas/label','datas/label_val',batch_size,shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6f200",
   "metadata": {},
   "source": [
    "### 新建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45be1b73",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m let\u001b[38;5;241m=\u001b[39m\u001b[43mResNet34\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "let=ResNet34().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd0357",
   "metadata": {},
   "source": [
    "### 训练(可中断，模型传入为地址)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cf9705b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m本函数使用了visdom以可视化数据\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m使用命令 python -m visdom.server 打开visdom\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m可视化训练效果网址：http://localhost:8097\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlearn_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 44\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, learn_rate, epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m logits\u001b[38;5;241m=\u001b[39mmodel(data)\n\u001b[1;32m     42\u001b[0m loss\u001b[38;5;241m=\u001b[39mloss_fun(logits,target)\n\u001b[0;32m---> 44\u001b[0m viz\u001b[38;5;241m.\u001b[39mline([\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m],[step_Tr],win\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,update\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "本函数使用了visdom以可视化数据\n",
    "使用命令 python -m visdom.server 打开visdom\n",
    "可视化训练效果网址：http://localhost:8097\n",
    "\"\"\"\n",
    "train(let,train_loader,test_loader,learn_rate,epochs,batch_size,\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa22ba6",
   "metadata": {},
   "source": [
    "# 网络验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c019a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate=1e-4   #学习率，防止过拟合\n",
    "epochs=800   #训练轮数\n",
    "batch_size=10   #数据集的划分量\n",
    "shuffle=True   #生成数据集时是否打乱\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net=ResNet34().to(device)\n",
    "model_load(net,\"models/83.95904541015625.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "945da439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread(\"1.jpg\")\n",
    "print(results_show(img,net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f01ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
